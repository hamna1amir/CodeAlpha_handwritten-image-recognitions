{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS_mq4yAlXHZ"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Helper function to display digit images\n",
        "def show_sample(images, labels, sample_count=25):\n",
        "  # Create a square with can fit {sample_count} images\n",
        "  grid_count = math.ceil(math.ceil(math.sqrt(sample_count)))\n",
        "  grid_count = min(grid_count, len(images), len(labels))\n",
        "\n",
        "  plt.figure(figsize=(2*grid_count, 2*grid_count))\n",
        "  for i in range(sample_count):\n",
        "    plt.subplot(grid_count, grid_count, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(images[i], cmap=plt.cm.gray)\n",
        "    plt.xlabel(labels[i])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5REuMrblewK"
      },
      "outputs": [],
      "source": [
        "# Download MNIST dataset.\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REY5lDDylpFh"
      },
      "outputs": [],
      "source": [
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAOE84IplyWR"
      },
      "outputs": [],
      "source": [
        "# Show the first 25 images in the training dataset.\n",
        "show_sample(train_images,\n",
        "            ['Label: %s' % label for label in train_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWgBGmaplzcp"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "\n",
        "# Optional: You can replace the dense layer above with the convolution layers below to get higher accuracy.\n",
        "    # keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "    # keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    # keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "    # keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    # keras.layers.Dropout(0.25),\n",
        "    # keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    # keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    # keras.layers.Dropout(0.5),\n",
        "\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6SOZuLRmEzS"
      },
      "outputs": [],
      "source": [
        "# Train the digit classification model\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJI8nqFWmMwC"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using test dataset.\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdlXEyUImeXC"
      },
      "outputs": [],
      "source": [
        "# Predict the labels of digit images in our test dataset.\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Then plot the first 25 test images and their predicted labels.\n",
        "show_sample(test_images,\n",
        "            ['Predicted: %d' % np.argmax(result) for result in predictions])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWROBI4iv9fY"
      },
      "source": [
        "## Convert the Keras model to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fXStjR4mzkR"
      },
      "outputs": [],
      "source": [
        "# Convert Keras model to TF Lite format.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TF Lite model as file\n",
        "f = open('mnist.tflite', \"wb\")\n",
        "f.write(tflite_model)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Z5yLxrwbpI"
      },
      "outputs": [],
      "source": [
        "# Download the digit classification model if you're using Colab,\n",
        "# or print the model's local path if you're not using Colab.\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('mnist.tflite')\n",
        "except ImportError:\n",
        "  import os\n",
        "  print('TF Lite model:', os.path.join(os.getcwd(), 'mnist.tflite'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFtIESwrx7cR"
      },
      "outputs": [],
      "source": [
        "# Download a test image\n",
        "zero_img_path = keras.utils.get_file(\n",
        "    'zero.png',\n",
        "    'https://storage.googleapis.com/khanhlvg-public.appspot.com/digit-classifier/zero.png'\n",
        ")\n",
        "image = keras.preprocessing.image.load_img(\n",
        "    zero_img_path,\n",
        "    color_mode = 'grayscale',\n",
        "    target_size=(28, 28),\n",
        "    interpolation='bilinear'\n",
        ")\n",
        "\n",
        "# Pre-process the image: Adding batch dimension and normalize the pixel value to [0..1]\n",
        "# In training, we feed images in a batch to the model to improve training speed, making the model input shape to be (BATCH_SIZE, 28, 28).\n",
        "# For inference, we still need to match the input shape with training, so we expand the input dimensions to (1, 28, 28) using np.expand_dims\n",
        "input_image = np.expand_dims(np.array(image, dtype=np.float32) / 255.0, 0)\n",
        "\n",
        "# Show the pre-processed input image\n",
        "show_sample(input_image, ['Input Image'], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPtbtEJ2uacB"
      },
      "outputs": [],
      "source": [
        "# Run inference with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], input_image)\n",
        "interpreter.invoke()\n",
        "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])()[0]\n",
        "\n",
        "# Print the model's classification result\n",
        "digit = np.argmax(output)\n",
        "print('Predicted Digit: %d\\nConfidence: %f' % (digit, output[digit]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Load the TF Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path='mnist.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Define the function to preprocess the image and perform inference\n",
        "def predict_digit(image):\n",
        "    # Preprocess the image\n",
        "    image = image.convert('L')  # Convert to grayscale\n",
        "    image = image.resize((28, 28))  # Resize to 28x28\n",
        "    input_image = np.expand_dims(np.array(image, dtype=np.float32) / 255.0, 0)\n",
        "\n",
        "    # Set the tensor and run inference\n",
        "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0]\n",
        "\n",
        "    # Get the predicted digit\n",
        "    digit = np.argmax(output)\n",
        "    confidence = output[digit]\n",
        "    return f'Predicted Digit: {digit}', confidence\n",
        "\n",
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_digit,\n",
        "    inputs=gr.Image(type='pil', label='Upload an image of a digit'),\n",
        "    outputs=[gr.Textbox(label='Predicted Digit'), gr.Textbox(label='Confidence')],\n",
        "    title='Digit Classifier',\n",
        "    description='Upload an image of a handwritten digit (0-9) and get the predicted digit and confidence score.'\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "4ad4kuXyK2AG",
        "outputId": "6a99400f-f59a-42e8-d909-ebfb71114b36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://65d41555b57c17b2e4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65d41555b57c17b2e4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_tflite.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}